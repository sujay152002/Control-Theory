{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d856e9-7442-49de-8a1b-02692a95634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting imports and dataset preparation...\n",
      "Datasets loaded.\n",
      "Starting training process...\n",
      "[Classifier Epoch 1] Loss: 204.2144\n",
      "[Classifier Epoch 2] Loss: 72.7412\n",
      "[Classifier Epoch 3] Loss: 49.0540\n",
      "[Classifier Epoch 4] Loss: 36.0197\n",
      "[Classifier Epoch 5] Loss: 27.8276\n",
      "üéØ Evaluation Accuracy: 0.9776\n",
      "\n",
      "Before Unlearning:\n",
      "Accuracy: 0.9776\n",
      "Graph built with 235146 nodes and 470280 edges.\n",
      "\n",
      "Attempt 1: Trying forget point idx 80 with label 9\n",
      "‚Üí Margin: 0.0797 | Feasible: Yes\n",
      "‚úÖ Forget point is feasible for unlearning.\n",
      "\n",
      "üîß Starting GCN training to forget data point (label: 9)\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch   1/50] Loss: 3.0776 | CE: 3.0482 | KL: 0.0294\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  10/50] Loss: 2.5271 | CE: 2.4999 | KL: 0.0272\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  20/50] Loss: 2.7109 | CE: 2.6861 | KL: 0.0248\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  30/50] Loss: 2.8793 | CE: 2.8567 | KL: 0.0226\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  40/50] Loss: 2.5714 | CE: 2.5510 | KL: 0.0205\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  50/50] Loss: 2.5872 | CE: 2.5687 | KL: 0.0185\n",
      "‚úÖ GCN training complete in 0.13s\n",
      "\n",
      "‚úÖ Forget point idx 80 accepted for unlearning.\n",
      "\n",
      "Applying mask to classifier weights for unlearning...\n",
      "Confidence before unlearning on forget point: 0.0312\n",
      "‚úÖ Mask applied to model weights.\n",
      "Confidence after unlearning on forget point: 0.1060\n",
      "üéØ Evaluation Accuracy: 0.9767\n",
      "\n",
      "After Unlearning:\n",
      "Accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "# Full OPM Implementation with Confidence Checks Before/After Unlearning\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.batch_size = 128\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = 5\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.9\n",
    "        self.mask_lr = 0.001\n",
    "        self.mask_epochs = 50\n",
    "        self.kl_coeff = 1.0\n",
    "        self.temperature = 0.5\n",
    "        self.top_k_ratio = 0.2\n",
    "        self.num_forget = 10\n",
    "        self.prior = 0.5\n",
    "        self.num_params = 0  # filled later\n",
    "        self.edge_index = None\n",
    "        self.overlap_threshold = 0.9  # cosine similarity threshold\n",
    "        self.max_attempts = 50\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Dataset and DataLoader\n",
    "print(\"Starting imports and dataset preparation...\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.test_batch_size, shuffle=False)\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Model\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# GCN for mask generation\n",
    "class GCNMaskNet(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, 32)\n",
    "        self.conv2 = GCNConv(32, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = torch.sigmoid(self.conv2(x, edge_index))\n",
    "        return x\n",
    "\n",
    "# Helper functions\n",
    "def copy_model(model):\n",
    "    return copy.deepcopy(model)\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    return F.cosine_similarity(x.view(1, -1), y.view(1, -1))\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    noise = torch.rand_like(logits)\n",
    "    gumbel = -torch.log(-torch.log(noise + 1e-20) + 1e-20)\n",
    "    return torch.sigmoid((logits + gumbel) / temperature)\n",
    "\n",
    "def kl_divergence(p, prior):\n",
    "    p = torch.clamp(p, 1e-6, 1 - 1e-6)\n",
    "    prior = torch.full_like(p, prior)\n",
    "    return (p * (p / prior).log() + (1 - p) * ((1 - p) / (1 - prior)).log()).mean()\n",
    "\n",
    "def apply_mask_to_model(model, mask, config):\n",
    "    offset = 0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            numel = param.numel()\n",
    "            param.data *= mask[offset:offset+numel].view(param.shape)\n",
    "            offset += numel\n",
    "    print(\"‚úÖ Mask applied to model weights.\")\n",
    "\n",
    "def train_classifier(model, loader, config):\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum)\n",
    "    for epoch in range(config.epochs):\n",
    "        total_loss = 0\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(config.device), target.to(config.device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"[Classifier Epoch {epoch+1}] Loss: {total_loss:.4f}\")\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(config.device), target.to(config.device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    acc = correct / len(loader.dataset)\n",
    "    print(f\"üéØ Evaluation Accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "def is_unlearning_feasible_margin(model, x, y, threshold=0.0):\n",
    "    output = model(x.unsqueeze(0))\n",
    "    probs = F.softmax(output, dim=1)\n",
    "    top2 = torch.topk(probs, 2).values.squeeze()\n",
    "    margin = top2[0] - top2[1]\n",
    "    print(f\"‚Üí Margin: {margin.item():.4f} | Feasible: {'Yes' if margin > threshold else 'No'}\")\n",
    "    return margin > threshold\n",
    "\n",
    "def check_mask_overlap(new_mask, previous_masks, threshold=0.9):\n",
    "    if not previous_masks:\n",
    "        return True\n",
    "    for i, prev in enumerate(previous_masks):\n",
    "        sim = cosine_similarity(new_mask, prev).item()\n",
    "        print(f\"‚Üí Cosine similarity with previous mask {i}: {sim:.4f}\")\n",
    "        if sim > threshold:\n",
    "            print(\"‚õî Overlap too high. Rejecting mask.\\n\")\n",
    "            return False\n",
    "    print(\"‚úÖ Mask is unique (overlap below threshold).\\n\")\n",
    "    return True\n",
    "\n",
    "def build_graph_from_model(model):\n",
    "    sizes = [param.numel() for param in model.parameters()]\n",
    "    total_params = sum(sizes)\n",
    "    config.num_params = total_params\n",
    "    x = torch.ones((total_params, 1)).to(config.device)\n",
    "    edge_index = []\n",
    "    idx = 0\n",
    "    for size in sizes:\n",
    "        for i in range(size - 1):\n",
    "            edge_index.append([idx + i, idx + i + 1])\n",
    "            edge_index.append([idx + i + 1, idx + i])\n",
    "        idx += size\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous().to(config.device)\n",
    "    config.edge_index = edge_index\n",
    "    print(f\"Graph built with {total_params} nodes and {edge_index.shape[1]} edges.\")\n",
    "\n",
    "def train_mask_generator(mask_net, classifier, forget_data, config):\n",
    "    mask_net.train()\n",
    "    optimizer = torch.optim.Adam(mask_net.parameters(), lr=config.mask_lr)\n",
    "\n",
    "    x_forget, y_forget = forget_data\n",
    "    x_forget = x_forget.to(config.device).unsqueeze(0)\n",
    "    y_forget = y_forget.to(config.device)\n",
    "\n",
    "    x_init = torch.ones(config.num_params, 1).to(config.device)\n",
    "    edge_index = config.edge_index.to(config.device)\n",
    "\n",
    "    print(f\"\\nüîß Starting GCN training to forget data point (label: {y_forget.item()})\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(config.mask_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        mask_logits = mask_net(x_init, edge_index).squeeze()\n",
    "        mask_probs = torch.sigmoid(mask_logits)\n",
    "        mask_sampled = gumbel_softmax_sample(mask_logits, temperature=config.temperature)\n",
    "\n",
    "        temp_model = copy_model(classifier).to(config.device)\n",
    "        apply_mask_to_model(temp_model, mask_sampled, config)\n",
    "\n",
    "        output = temp_model(x_forget)\n",
    "        ce_loss = F.cross_entropy(output, y_forget.unsqueeze(0))\n",
    "        kl = kl_divergence(mask_probs, config.prior)\n",
    "\n",
    "        loss = ce_loss + config.kl_coeff * kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"[Epoch {epoch+1:3d}/{config.mask_epochs}] Loss: {loss.item():.4f} | CE: {ce_loss.item():.4f} | KL: {kl.item():.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"‚úÖ GCN training complete in {end_time - start_time:.2f}s\\n\")\n",
    "    return mask_logits.detach()\n",
    "\n",
    "def main():\n",
    "    print(\"Starting training process...\")\n",
    "    classifier = SimpleClassifier().to(config.device)\n",
    "    train_classifier(classifier, train_loader, config)\n",
    "\n",
    "    acc_before = evaluate_model(classifier, test_loader)\n",
    "    print(f\"\\nBefore Unlearning:\\nAccuracy: {acc_before:.4f}\")\n",
    "\n",
    "    # Build graph once after training\n",
    "    build_graph_from_model(classifier)\n",
    "\n",
    "    accepted_masks = []\n",
    "    forget_x, forget_y, forget_idx, forget_mask = None, None, None, None\n",
    "\n",
    "    for attempt in range(1, config.max_attempts + 1):\n",
    "        idx = random.randint(0, len(train_dataset) - 1)\n",
    "        x_i, y_i = train_dataset[idx]\n",
    "        x_i = x_i.to(config.device)\n",
    "        y_i = torch.tensor(y_i).to(config.device)\n",
    "        print(f\"\\nAttempt {attempt}: Trying forget point idx {idx} with label {y_i.item()}\")\n",
    "\n",
    "        if not is_unlearning_feasible_margin(classifier, x_i, y_i):\n",
    "            print(\"‚ùå Not feasible by margin, trying another point...\")\n",
    "            continue\n",
    "\n",
    "        print(\"‚úÖ Forget point is feasible for unlearning.\")\n",
    "\n",
    "        mask_net = GCNMaskNet(1).to(config.device)\n",
    "        mask_logits = train_mask_generator(mask_net, classifier, (x_i, y_i), config)\n",
    "\n",
    "        if not check_mask_overlap(mask_logits, accepted_masks, config.overlap_threshold):\n",
    "            print(\"‚ùå Mask overlap too high, trying next point...\")\n",
    "            continue\n",
    "\n",
    "        print(f\"‚úÖ Forget point idx {idx} accepted for unlearning.\")\n",
    "        accepted_masks.append(mask_logits)\n",
    "        forget_x, forget_y, forget_idx, forget_mask = x_i, y_i, idx, mask_logits\n",
    "        break\n",
    "    else:\n",
    "        print(\"‚ùå No feasible forget point found within max attempts passing overlap checks.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nApplying mask to classifier weights for unlearning...\")\n",
    "    # Confidence before applying mask\n",
    "    output_before = classifier(forget_x.unsqueeze(0))\n",
    "    conf_before = F.softmax(output_before, dim=1)[0, forget_y].item()\n",
    "    print(f\"Confidence before unlearning on forget point: {conf_before:.4f}\")\n",
    "\n",
    "    apply_mask_to_model(classifier, forget_mask, config)\n",
    "\n",
    "    # Confidence after applying mask\n",
    "    output_after = classifier(forget_x.unsqueeze(0))\n",
    "    conf_after = F.softmax(output_after, dim=1)[0, forget_y].item()\n",
    "    print(f\"Confidence after unlearning on forget point: {conf_after:.4f}\")\n",
    "\n",
    "    acc_after = evaluate_model(classifier, test_loader)\n",
    "    print(f\"\\nAfter Unlearning:\\nAccuracy: {acc_after:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487ac960-65fc-449f-8947-ab643c319420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting imports and dataset preparation...\n",
      "Datasets loaded.\n",
      "Starting training process...\n",
      "[Classifier Epoch 1] Loss: 204.2144\n",
      "[Classifier Epoch 2] Loss: 72.7412\n",
      "[Classifier Epoch 3] Loss: 49.0540\n",
      "[Classifier Epoch 4] Loss: 36.0197\n",
      "[Classifier Epoch 5] Loss: 27.8276\n",
      "üéØ Evaluation Accuracy: 0.9776\n",
      "\n",
      "Before Unlearning:\n",
      "Accuracy: 0.9776\n",
      "Graph built with 235146 nodes and 470280 edges.\n",
      "\n",
      "Attempt 1: Trying forget point idx 80 with label 9\n",
      "‚Üí Margin: 0.0797 | Feasible: Yes\n",
      "‚úÖ Forget point is feasible for unlearning.\n",
      "\n",
      "üîß Starting GCN training to forget data point (label: 9)\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch   1/50] Loss: 3.0776 | CE: 3.0482 | KL: 0.0294\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  10/50] Loss: 2.5271 | CE: 2.4999 | KL: 0.0272\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  20/50] Loss: 2.7109 | CE: 2.6861 | KL: 0.0248\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  30/50] Loss: 2.8793 | CE: 2.8567 | KL: 0.0226\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  40/50] Loss: 2.5714 | CE: 2.5510 | KL: 0.0205\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "‚úÖ Mask applied to model weights.\n",
      "[Epoch  50/50] Loss: 2.5872 | CE: 2.5687 | KL: 0.0185\n",
      "‚úÖ GCN training complete in 0.22s\n",
      "\n",
      "‚úÖ Forget point idx 80 accepted for unlearning.\n",
      "\n",
      "Applying mask to classifier weights for unlearning...\n",
      "\n",
      "üìä Confidence BEFORE unlearning on forget point (label 9):\n",
      "  Class 0: 0.3836\n",
      "  Class 1: 0.0030\n",
      "  Class 2: 0.0110\n",
      "  Class 3: 0.0277\n",
      "  Class 4: 0.0004\n",
      "  Class 5: 0.1966\n",
      "  Class 6: 0.0417\n",
      "  Class 7: 0.0009\n",
      "  Class 8: 0.3039\n",
      "  Class 9: 0.0312\n",
      "‚Üí Target Class 9 Confidence: 0.0312\n",
      "\n",
      "‚úÖ Mask applied to model weights.\n",
      "\n",
      "üìä Confidence AFTER unlearning on forget point (label 9):\n",
      "  Class 0: 0.1112\n",
      "  Class 1: 0.0880\n",
      "  Class 2: 0.0969\n",
      "  Class 3: 0.1031\n",
      "  Class 4: 0.0813\n",
      "  Class 5: 0.1134\n",
      "  Class 6: 0.1020\n",
      "  Class 7: 0.0815\n",
      "  Class 8: 0.1165\n",
      "  Class 9: 0.1060\n",
      "‚Üí Target Class 9 Confidence: 0.1060\n",
      "\n",
      "üéØ Evaluation Accuracy: 0.9767\n",
      "\n",
      "After Unlearning:\n",
      "Accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.batch_size = 128\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = 5\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.9\n",
    "        self.mask_lr = 0.001\n",
    "        self.mask_epochs = 50\n",
    "        self.kl_coeff = 1.0\n",
    "        self.temperature = 0.5\n",
    "        self.top_k_ratio = 0.2\n",
    "        self.num_forget = 10\n",
    "        self.prior = 0.5\n",
    "        self.num_params = 0  # filled later\n",
    "        self.edge_index = None\n",
    "        self.overlap_threshold = 0.9\n",
    "        self.max_attempts = 50\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Dataset and DataLoader\n",
    "print(\"Starting imports and dataset preparation...\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.test_batch_size, shuffle=False)\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Model definition\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# GCN for mask generation\n",
    "class GCNMaskNet(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, 32)\n",
    "        self.conv2 = GCNConv(32, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = torch.sigmoid(self.conv2(x, edge_index))\n",
    "        return x\n",
    "\n",
    "# Helper functions\n",
    "def copy_model(model):\n",
    "    return copy.deepcopy(model)\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    return F.cosine_similarity(x.view(1, -1), y.view(1, -1))\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    noise = torch.rand_like(logits)\n",
    "    gumbel = -torch.log(-torch.log(noise + 1e-20) + 1e-20)\n",
    "    return torch.sigmoid((logits + gumbel) / temperature)\n",
    "\n",
    "def kl_divergence(p, prior):\n",
    "    p = torch.clamp(p, 1e-6, 1 - 1e-6)\n",
    "    prior = torch.full_like(p, prior)\n",
    "    return (p * (p / prior).log() + (1 - p) * ((1 - p) / (1 - prior)).log()).mean()\n",
    "\n",
    "def apply_mask_to_model(model, mask, config):\n",
    "    offset = 0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            numel = param.numel()\n",
    "            param.data *= mask[offset:offset+numel].view(param.shape)\n",
    "            offset += numel\n",
    "    print(\"‚úÖ Mask applied to model weights.\")\n",
    "\n",
    "def train_classifier(model, loader, config):\n",
    "    model.train()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum)\n",
    "    for epoch in range(config.epochs):\n",
    "        total_loss = 0\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(config.device), target.to(config.device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"[Classifier Epoch {epoch+1}] Loss: {total_loss:.4f}\")\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(config.device), target.to(config.device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    acc = correct / len(loader.dataset)\n",
    "    print(f\"üéØ Evaluation Accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "def is_unlearning_feasible_margin(model, x, y, threshold=0.0):\n",
    "    output = model(x.unsqueeze(0))\n",
    "    probs = F.softmax(output, dim=1)\n",
    "    top2 = torch.topk(probs, 2).values.squeeze()\n",
    "    margin = top2[0] - top2[1]\n",
    "    print(f\"‚Üí Margin: {margin.item():.4f} | Feasible: {'Yes' if margin > threshold else 'No'}\")\n",
    "    return margin > threshold\n",
    "\n",
    "def check_mask_overlap(new_mask, previous_masks, threshold=0.9):\n",
    "    if not previous_masks:\n",
    "        return True\n",
    "    for i, prev in enumerate(previous_masks):\n",
    "        sim = cosine_similarity(new_mask, prev).item()\n",
    "        print(f\"‚Üí Cosine similarity with previous mask {i}: {sim:.4f}\")\n",
    "        if sim > threshold:\n",
    "            print(\"‚õî Overlap too high. Rejecting mask.\\n\")\n",
    "            return False\n",
    "    print(\"‚úÖ Mask is unique (overlap below threshold).\\n\")\n",
    "    return True\n",
    "\n",
    "def build_graph_from_model(model):\n",
    "    sizes = [param.numel() for param in model.parameters()]\n",
    "    total_params = sum(sizes)\n",
    "    config.num_params = total_params\n",
    "    x = torch.ones((total_params, 1)).to(config.device)\n",
    "    edge_index = []\n",
    "    idx = 0\n",
    "    for size in sizes:\n",
    "        for i in range(size - 1):\n",
    "            edge_index.append([idx + i, idx + i + 1])\n",
    "            edge_index.append([idx + i + 1, idx + i])\n",
    "        idx += size\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous().to(config.device)\n",
    "    config.edge_index = edge_index\n",
    "    print(f\"Graph built with {total_params} nodes and {edge_index.shape[1]} edges.\")\n",
    "\n",
    "def train_mask_generator(mask_net, classifier, forget_data, config):\n",
    "    mask_net.train()\n",
    "    optimizer = torch.optim.Adam(mask_net.parameters(), lr=config.mask_lr)\n",
    "\n",
    "    x_forget, y_forget = forget_data\n",
    "    x_forget = x_forget.to(config.device).unsqueeze(0)\n",
    "    y_forget = y_forget.to(config.device)\n",
    "\n",
    "    x_init = torch.ones(config.num_params, 1).to(config.device)\n",
    "    edge_index = config.edge_index.to(config.device)\n",
    "\n",
    "    print(f\"\\nüîß Starting GCN training to forget data point (label: {y_forget.item()})\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(config.mask_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        mask_logits = mask_net(x_init, edge_index).squeeze()\n",
    "        mask_probs = torch.sigmoid(mask_logits)\n",
    "        mask_sampled = gumbel_softmax_sample(mask_logits, temperature=config.temperature)\n",
    "\n",
    "        temp_model = copy_model(classifier).to(config.device)\n",
    "        apply_mask_to_model(temp_model, mask_sampled, config)\n",
    "\n",
    "        output = temp_model(x_forget)\n",
    "        ce_loss = F.cross_entropy(output, y_forget.unsqueeze(0))\n",
    "        kl = kl_divergence(mask_probs, config.prior)\n",
    "\n",
    "        loss = ce_loss + config.kl_coeff * kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"[Epoch {epoch+1:3d}/{config.mask_epochs}] Loss: {loss.item():.4f} | CE: {ce_loss.item():.4f} | KL: {kl.item():.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"‚úÖ GCN training complete in {end_time - start_time:.2f}s\\n\")\n",
    "    return mask_logits.detach()\n",
    "\n",
    "def main():\n",
    "    print(\"Starting training process...\")\n",
    "    classifier = SimpleClassifier().to(config.device)\n",
    "    train_classifier(classifier, train_loader, config)\n",
    "\n",
    "    acc_before = evaluate_model(classifier, test_loader)\n",
    "    print(f\"\\nBefore Unlearning:\\nAccuracy: {acc_before:.4f}\")\n",
    "\n",
    "    build_graph_from_model(classifier)\n",
    "\n",
    "    accepted_masks = []\n",
    "    forget_x, forget_y, forget_idx, forget_mask = None, None, None, None\n",
    "\n",
    "    for attempt in range(1, config.max_attempts + 1):\n",
    "        idx = 80  # random.randint(0, len(train_dataset) - 1) for random point\n",
    "        x_i, y_i = train_dataset[idx]\n",
    "        x_i = x_i.to(config.device)\n",
    "        y_i = torch.tensor(y_i).to(config.device)\n",
    "        print(f\"\\nAttempt {attempt}: Trying forget point idx {idx} with label {y_i.item()}\")\n",
    "\n",
    "        if not is_unlearning_feasible_margin(classifier, x_i, y_i):\n",
    "            print(\"‚ùå Not feasible by margin, trying another point...\")\n",
    "            continue\n",
    "\n",
    "        print(\"‚úÖ Forget point is feasible for unlearning.\")\n",
    "\n",
    "        mask_net = GCNMaskNet(1).to(config.device)\n",
    "        mask_logits = train_mask_generator(mask_net, classifier, (x_i, y_i), config)\n",
    "\n",
    "        if not check_mask_overlap(mask_logits, accepted_masks, config.overlap_threshold):\n",
    "            print(\"‚ùå Mask overlap too high, trying next point...\")\n",
    "            continue\n",
    "\n",
    "        print(f\"‚úÖ Forget point idx {idx} accepted for unlearning.\")\n",
    "        accepted_masks.append(mask_logits)\n",
    "        forget_x, forget_y, forget_idx, forget_mask = x_i, y_i, idx, mask_logits\n",
    "        break\n",
    "    else:\n",
    "        print(\"‚ùå No feasible forget point found within max attempts passing overlap checks.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nApplying mask to classifier weights for unlearning...\")\n",
    "\n",
    "    # Confidence BEFORE unlearning (per class)\n",
    "    output_before = classifier(forget_x.unsqueeze(0))\n",
    "    probs_before = F.softmax(output_before, dim=1).squeeze().tolist()\n",
    "    print(f\"\\nüìä Confidence BEFORE unlearning on forget point (label {forget_y.item()}):\")\n",
    "    for cls, prob in enumerate(probs_before):\n",
    "        print(f\"  Class {cls}: {prob:.4f}\")\n",
    "    conf_before = probs_before[forget_y.item()]\n",
    "    print(f\"‚Üí Target Class {forget_y.item()} Confidence: {conf_before:.4f}\\n\")\n",
    "\n",
    "    apply_mask_to_model(classifier, forget_mask, config)\n",
    "\n",
    "    # Confidence AFTER unlearning (per class)\n",
    "    output_after = classifier(forget_x.unsqueeze(0))\n",
    "    probs_after = F.softmax(output_after, dim=1).squeeze().tolist()\n",
    "    print(f\"\\nüìä Confidence AFTER unlearning on forget point (label {forget_y.item()}):\")\n",
    "    for cls, prob in enumerate(probs_after):\n",
    "        print(f\"  Class {cls}: {prob:.4f}\")\n",
    "    conf_after = probs_after[forget_y.item()]\n",
    "    print(f\"‚Üí Target Class {forget_y.item()} Confidence: {conf_after:.4f}\\n\")\n",
    "\n",
    "    acc_after = evaluate_model(classifier, test_loader)\n",
    "    print(f\"\\nAfter Unlearning:\\nAccuracy: {acc_after:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c9fd1-8aa5-485a-bcd8-995b35f60f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
